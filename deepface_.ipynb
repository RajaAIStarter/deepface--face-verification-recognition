{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Face Verification Example with DeepFace\n",
        "This repository demonstrates face verification using DeepFace with considerations for different approaches and trade-offs."
      ],
      "metadata": {
        "id": "z9s2vnxoRKM6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8iHXTAVNJpS"
      },
      "outputs": [],
      "source": [
        "!pip install deepface opencv-python numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FoDh-Y1O9op",
        "outputId": "c976d842-a7de-47c9-ff91-48ea0a9d801c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install unzip if not already installed\n",
        "!apt-get install unzip\n",
        "\n",
        "# Unzip the file\n",
        "!unzip -q '/content/images.zip' -d '/content/extracted_images'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Embeddings from images folder"
      ],
      "metadata": {
        "id": "CI5jP-EyLe6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HRUmvyPMOGW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4758a600-3d17-478b-8d19-7148e680a112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-02-04 12:50:08 - vgg_face_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/vgg_face_weights.h5\n",
            "To: /root/.deepface/weights/vgg_face_weights.h5\n",
            "100%|██████████| 580M/580M [00:03<00:00, 155MB/s] \n"
          ]
        }
      ],
      "source": [
        "from deepface import DeepFace\n",
        "import os\n",
        "\n",
        "# Path to your face database\n",
        "db_path = \"/content/extracted_images/images\"\n",
        "embeddings = []\n",
        "\n",
        "# Extract embeddings for each image\n",
        "for img_name in os.listdir(db_path):\n",
        "    img_path = os.path.join(db_path, img_name)\n",
        "    #change different embeddings extraction models for your requirement\n",
        "    embedding = DeepFace.represent(img_path, model_name=\"VGG-Face\")[0][\"embedding\"]\n",
        "    embeddings.append(embedding)\n",
        "\n",
        "# Save embeddings to a file (using numpy)\n",
        "import numpy as np\n",
        "np.save(\"my_embeddings.npy\", embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the verification with new data , adjust the thresholds."
      ],
      "metadata": {
        "id": "KgbfLrCQLwdP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xhmg3lOQPRgQ",
        "outputId": "e2407419-eef2-43ff-b981-bbd380a67de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the same person? True\n"
          ]
        }
      ],
      "source": [
        "# Load your stored embeddings\n",
        "stored_embeddings = np.load(\"my_embeddings.npy\")\n",
        "\n",
        "# Path to the new test image\n",
        "test_img_path = \"/content/unknown1.jpg\" #test with new elon musk images that not in images folder\n",
        "\n",
        "# Extract embedding of the test image\n",
        "test_embedding = DeepFace.represent(test_img_path, model_name=\"VGG-Face\", detector_backend='opencv')[0][\"embedding\"] #change the models and detectors based on your requirement\n",
        "\n",
        "# Compare with stored embeddings (using cosine similarity)\n",
        "from numpy.linalg import norm\n",
        "\n",
        "similarities = []\n",
        "for emb in stored_embeddings:\n",
        "    similarity = np.dot(emb, test_embedding) / (norm(emb) * norm(test_embedding))\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# Check if any similarity is above a threshold (e.g., 0.7)\n",
        "threshold = 0.5\n",
        "is_verified = max(similarities) > threshold\n",
        "print(f\"Is the same person? {is_verified}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE: Every time you change the models remove the my_embeddings.npy file then run the code to extract the embeddings with new model otherwise embeddings are mixed up and drops performance.**\n",
        "\n",
        "**In application-level face verification, selecting the appropriate model depends on your specific requirements, such as on-device processing, cloud integration, or GPU support. It's important to balance model performance with inference time to meet your application's needs.**\n",
        "\n",
        "**When you extract embeddings from a face and search through a database for matches, the process is known as face recognition. In our case, using a limited set of images (e.g., five) for matching is referred to as face verification.**\n",
        "\n",
        "**There are numerous pretrained models available for face recognition tasks. Alternatively, you can train a model from scratch using convolutional neural networks (CNNs). For instance, OpenCV provides tools for face recognition, and you can find tutorials on implementing face recognition with OpenCV and Python. Additionally, cloud-based face recognition services offer user-friendly solutions but may involve ongoing costs and raise privacy concerns.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mHtaFVpeRIOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Comparison Table**\n",
        "\n",
        "Recommended Use Case\n",
        "\n",
        "Model\t     __ Accuracy __ Speed\t__ Input __  Size\n",
        "\n",
        "\n",
        "VGG-Face    |High\tSlow\t |224x224\t  |High accuracy requirements\n",
        "\n",
        "Facenet\t  |Very High\t    |Medium\t  |160x160\tProduction systems\n",
        "\n",
        "OpenFace\t|Medium\tFast    |96x96\t    |Mobile/Edge devices\n",
        "\n",
        "DeepID\t  |High\tFast\t |55x47\t    |Low-resource environments\n",
        "\n",
        "ArcFace\t  |SOTA\tSlow\t |112x112\t  |Cutting-edge applications\n",
        "\n",
        "\n",
        "#Detector Backends\n",
        "* OpenCV: Fast but less accurate\n",
        "\n",
        "* SSD: Balance of speed and accuracy\n",
        "\n",
        "* MTCNN: Slower but handles difficult angles\n",
        "\n",
        "* RetinaFace: Most accurate (especially for occluded faces) but slowest\n"
      ],
      "metadata": {
        "id": "gwwVHo6dP6lF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Threshold Guide**\n",
        "\n",
        "Model _\tCosine Threshold _ Euclidean Threshold\n",
        "\n",
        "VGG-Face\t0.4\t0.55\n",
        "\n",
        "Facenet\t0.3\t0.75\n",
        "\n",
        "OpenFace\t0.1\t0.9\n",
        "\n",
        "ArcFace\t0.4\t0.5\n",
        "\n",
        "\n",
        "In face recognition systems, similarity scores such as cosine similarity and Euclidean distance are commonly used to compare facial embeddings. However, these scores alone may not provide a complete picture of a model's performance due to variations in how different models extract and represent embeddings. Therefore, it's essential to employ comprehensive evaluation metrics to assess the effectiveness of face recognition models accurately.\n",
        "\n",
        "**Evaluation Metrics:**\n",
        "\n",
        "**Accuracy:** Measures the proportion of correct predictions (both true positives and true negatives) out of all predictions. While straightforward, accuracy can be misleading, especially with imbalanced datasets.\n",
        "\n",
        "**Precision:** Indicates the proportion of true positive identifications among all positive identifications made by the model. High precision means fewer false positives.\n",
        "\n",
        "**Recall (Sensitivity):** Reflects the proportion of true positive identifications among all actual positive instances. High recall indicates fewer false negatives.\n",
        "\n",
        "**F1 Score:** The harmonic mean of precision and recall, providing a single metric that balances both concerns. It's particularly useful when dealing with imbalanced datasets.\n",
        "\n",
        "**Receiver Operating Characteristic (ROC) Curve and Area Under the Curve (AUC):** The ROC curve plots the true positive rate against the false positive rate at various threshold settings, and the AUC summarizes the overall ability of the model to discriminate between positive and negative classes.\n",
        "\n",
        "**Manual Testing:**\n",
        "\n",
        "Beyond quantitative metrics, manual testing is crucial to ensure the model meets specific user requirements. This involves evaluating the model's performance on a diverse set of images, including variations in lighting, angles, expressions, and occlusions, to identify potential weaknesses and areas for improvement.\n",
        "\n",
        "By combining similarity scores with these evaluation metrics and thorough manual testing, you can gain a more comprehensive understanding of a face recognition model's performance and its suitability for your specific application."
      ],
      "metadata": {
        "id": "edZ6xGR8SUqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performance Considerations\n",
        "\n",
        "**Embedding Extraction:**\n",
        "\n",
        "Fastest: OpenFace (~300ms/face on CPU)\n",
        "\n",
        "Slowest: ArcFace (~1.2s/face on CPU)\n",
        "\n",
        "**Memory Usage:**\n",
        "\n",
        "Lightest: OpenFace (4.3MB model)\n",
        "\n",
        "Heaviest: VGG-Face (528MB model)\n",
        "\n",
        "**Alternative Approaches**\n",
        "\n",
        "Real-Time Verification:\n",
        "\n"
      ],
      "metadata": {
        "id": "F6O147CDZA0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'model_name': 'OpenFace',\n",
        "    'detector_backend': 'ssd',\n",
        "    'threshold': 0.2\n",
        "}"
      ],
      "metadata": {
        "id": "Zyt5TXLvZLVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "High-Security Systems:"
      ],
      "metadata": {
        "id": "1EvRrLO5ZMD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'model_name': 'ArcFace',\n",
        "    'detector_backend': 'retinaface',\n",
        "    'threshold': 0.5\n",
        "}"
      ],
      "metadata": {
        "id": "x6USGua6ZOoz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}